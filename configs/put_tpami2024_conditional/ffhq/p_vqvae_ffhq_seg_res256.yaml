model:
  target: image_synthesis.modeling.codecs.image_codec.patch_vqgan.PatchVQGAN
  params:
    trainable: True
    token_shape: [32, 32]
    im_process_info:
      scale: [76.5]
      mean: [1.0] # imagenet RGB mean
      std: [1.0]

    quantizer_config:
      target: image_synthesis.modeling.codecs.image_codec.patch_vqgan.VectorQuantizer
      params:
        n_e: 512
        e_dim: 256
        masked_embed_start: 512
        embed_ema: True
        get_embed_type: retrive
        distance_type: euclidean
    
        gumbel_sample: false

    
    encoder_config: 
      target: image_synthesis.modeling.codecs.image_codec.patch_vqgan.PatchEncoder2
      params:
        in_ch: 1
        res_ch: 256
        out_ch: 256
        num_res_block: 8
        stride: 8
    decoder_config:
      target: image_synthesis.modeling.codecs.image_codec.patch_vqgan.PatchConvDecoder2
      params:
        in_ch: 256
        out_ch: 1
        res_ch: 256
        num_res_block: 2
        num_res_block_after_resolution_change: 2
        stride: 8
        up_layer_with_image: false
        upsample_type: nearest
    lossconfig:
      target: image_synthesis.modeling.modules.edge_connect.losses.EdgeConnectLoss
      params:
        in_channels: 1
        gan_loss: nsgan
        g_gradient_loss_weight: 2.0
        g_content_loss_weight: 0.0
        g_style_loss_weight: 0.0
        g_adv_loss_weight: 0.05
        disc_start: 15000
        content_start: 15000
        style_start: 15000
        gradient_start: 15000
        norm_to_0_1: False
        
solver:
  base_lr: 0.0
  adjust_lr: none # not adjust lr according to total batch_size
  max_epochs: 100
  save_epochs: 5
  validation_epochs: 1
  sample_iterations: epoch     # how many iterations to perform sampling once ?
  optimizers_and_schedulers: # a list of configures, so we can config several optimizers and schedulers
  - name: generator 
    optimizer:
      target: torch.optim.Adam
      params: 
        betas: !!python/tuple [0.0, 0.9]
    scheduler:
      step_iteration: 1
      target: image_synthesis.engine.lr_scheduler.CosineAnnealingLRWithWarmup
      params:
        min_lr: 1.0e-6
        warmup_lr: 2.0e-4 # the lr to be touched after warmup
        warmup: 5000 
  - name: discriminator 
    # start_iteration: 5000 
    optimizer:
      target: torch.optim.Adam
      params: 
        betas: !!python/tuple [0.0, 0.9]
    scheduler:
      step_iteration: 1
      target: image_synthesis.engine.lr_scheduler.CosineAnnealingLRWithWarmup
      params:
        min_lr: 1.0e-6
        warmup_lr: 2.0e-5 # the lr to be touched after warmup
        warmup: 5000 


dataloader:
  data_root: data
  batch_size: 28
  num_workers: 4
  train_datasets:
    - target: image_synthesis.data.image_list_dataset.ImageListDataset
      params:
        name: ffhq
        image_list_file: data/ffhqtrain_69k.txt
        image_end_with: bmp,jpg,jpeg,pgm,png,ppm,tif,tiff,webp,JPEG

        mode: L
        unknow_class_param:
          num_unknow_classes: 5
          prob_unknow: 0.7
          max_number: 5
          unknow_start: 133

        load_segmentation_map: false
        load_sketch_map: False

        mask: -1.0
        mask_low_to_high: 0.0
        mask_low_size: None
        zero_mask: 0.0
        multi_image_mask: False 
        erase_image_with_mask: -1.0
        return_data_keys: [image,]
        stroken_mask_params: None # 8*8 we set the receptive field as the min masked area
        im_preprocessor_config:
          target: image_synthesis.data.utils.image_preprocessor.SimplePreprocessor
          params:
            size: [256, 256]
            smallest_max_size: 272
            random_crop: True
            horizon_flip: True
            mode: L

  validation_datasets:
    - target: image_synthesis.data.image_list_dataset.ImageListDataset
      params:
        name: ffhq
        image_list_file: data/ffhqvalidation_1k.txt
        image_end_with: bmp,jpg,jpeg,pgm,png,ppm,tif,tiff,webp,JPEG

        mode: L

        mask: -1.0
        mask_low_to_high: 0.0
        mask_low_size: None
        zero_mask: 0.0
        multi_image_mask: False 
        erase_image_with_mask: -1.0
        return_data_keys: [image,]
        stroken_mask_params: None # 8*8 we set the receptive field as the min masked area
        
        unknow_class_param:
          num_unknow_classes: 5
          prob_unknow: 0.7
          max_number: 5
          unknow_start: 133

        load_segmentation_map: false
        load_sketch_map: False

        im_preprocessor_config:
          target: image_synthesis.data.utils.image_preprocessor.SimplePreprocessor
          params:
            size: [256, 256]
            smallest_max_size: 256
            mode: L